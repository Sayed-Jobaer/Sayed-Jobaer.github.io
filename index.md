# Welcome to Dawei Li's Homepage!
---
layout: default
---

## Foysal Ahmed

**PhD Student**  
**Donghua University (211, Double First-Class) ¬∑ Shanghai, China** <br>

üìß **Email:** [foysal.9@outlook.com](mailto:foysal.9@outlook.com)  <br>
üåê **GitHub:** [github.com/foysalahmed10](https://github.com/foysalahmed10)  <br>
üìÑ **CV:** [Download CV](cv.pdf)  <br>
üéì **Google Scholar:** [Google Scholar Profile](https://scholar.google.com/citations?user=1HUchzEAAAAJ&hl=en)

---

## Academic History and Education Background

I received my **Bachelor‚Äôs degree in Software Engineering** from **Daffodil International University**, Bangladesh, in **2018**. In **September 2019**, I was awarded the **Chinese Government Scholarship** and moved to China to pursue graduate studies. I completed my **Master‚Äôs degree in Information and Communication Engineering** at **Donghua University**, Shanghai, China, in **2022**. Following my master‚Äôs studies, I was awarded the **Shanghai Government Scholarship** to pursue my **PhD** at **Donghua University**. I am currently a PhD student in the **Information and Communication Intelligent Systems** program, where my research focuses on data-driven methods for **3D plant phenotyping, 3D point cloud processing, generative modeling and computer vision**.


## Academic History and Education Background:
<p>I received B.E. in Automation in 2006 from Tongji University, Shanghai, China. During 2009-2010, I was a visiting researcher at Michigan State University, East Lansing, MI, USA. In 2013, I received the Ph.D. in Control Theory and Control Engineering from Tongji University, Shanghai, China. During 2013-2015, I was a postdoc at the Department of Computer Sciences and Technology, Tongji University, Shanghai, China. Currently an associate professor with Donghua University, Songjiang District, Shanghai, China. </p>

<!-- Ê≥®ÈáäÊéâËØ•Âè• <p>‚û§ <a href=""><strong></strong></a></p>  -->

## Research Interests:
<p>Image Processing, Point Cloud Processing, Artificial Intelligence, Intelligent Visual Surveillance, and Plant Phenotyping.</p>

## Teaching:
<p><i>Semester A (Autumn): </i></p>
<p>1.	Data Analysis and Machine Learning (for graduate students). </p>
<p>2.	Pattern Recognition Principles and Techniques (for international student/joint course with Dr. Huang).</p>
<p>3.	Frontiers of AI (for undergraduates).</p>
<p>4.	Professional Introduction (for undergraduates).</p>
<p><i>Semester B (Spring): </i></p>
<p>1.	Machine Learning (for undergraduates).</p>
<p>2.	Production Practice for AI (for undergraduates/joint course with Dr. Pan).</p>

## Research Projects and Talent Programs:
<p>1.	Shanghai Rising-Star Program, Person in Charge. (07/2021-06/2024).</p>
<p>2.	‚ÄúResearch on the stereo imaging for plant phenotyping and genotype analysis‚Äù, Natural Science Foundation of Shanghai, Person in Charge. (07/2020-06/2023).</p>
<p>3.	‚Äú3D imaging for analyzing the phenotypes of textile plants‚Äù, The Fundamental Research Funds for the Central Universities of China (special base project), Person in Charge. (01/2019-04/2020)</p>
<p>4.	‚ÄúResearch of illumination-robust stereo vision algorithm for greenhouse plants‚Äù, National Natural Science Foundation of China, Person in Charge. (01/2017-12/2019).</p>
<p>5.	Shanghai Sailing Program, Person in Charge. (06/2016-05/2019).</p>
<p>6.	‚ÄúResearch on illumination-robust stereo vision imaging tools for greenhouse plants‚Äù, The Fundamental Research Funds for the Central Universities of China, Person in Charge. (01/2016-12/2018)</p>
<p>7.	‚ÄúA research on digitization and virtual visualization of greenhouse tomato plants‚Äù, China Postdoctoral Science Foundation Special Grants, Person in Charge. (07/2014-07/2015).</p>
<p>8.	‚ÄúResearch on key technology in an intelligent video surveillance system‚Äù, Shanghai Yangpu District Innovation and Practice base project for postdocs, Person in Charge. (02/2014-12/2014).</p>
<p>9.	‚ÄúThe research of digitized imaging and virtual visualization technologies on greenhouse plants‚Äù, China Postdoctoral Science Foundation 1st class grants, Person in Charge. (07/2013-12/2014).</p>

## Academic Participation:
<p>1.	Chinese Society of Agricultural Engineering, Senior Member.</p>
<p>2.	Chinese Association of Automation, Member.</p>
<p>3.	Shanghai Agricultural Engineering Association, Standing Director.</p>
<p>4.	IEEE, Member.</p>
<p>5.	IEEE CIS Shanghai Chapter, Secretary General.</p>
<p>6.	Reviewer for a number of international conferences and journals including <i>IEEE SPL, IEEE TCSVT, IEEE TMM, IEEE TCYB, IEEE ACCESS, IEEE RA-L, Graphics & Visual Computing, Plant Phenomics, Integrated Computer-Aided Engineering, Neurocomputing, IJPRAI, Applied Engineering in Agriculture (ASABE), Ecological Informatics, The Visual Computer, Automation in Construction, China Communications, International Journal of Remote Sensing, Scientific Programming, Frontiers in Plant Science, and NCAA.</i></p>

## Honors and Awards:
<p>1.	Best Paper Award for Young Researchers at The Annual Academic Conference of Chinese Society of Agricultural Engineering (3/4), Zhenjiang, China. (08/2013)</p>
<p>2.	Best Doctoral Dissertation Award of Year 2013 (Top 28 among 592, 1/1), Tongji University, Shanghai, China. (05/2013)</p>
<p>3.	Finalist for Best Paper Award (Top 6 among 899, 1/3) in the 11th International Conference on Control, Automation, Robotics and Vision (ICARCV2010), Singapore. (12/2010)</p>

## Selected Publications:

<p>[1] <b>D. Li</b>‚Ä†, F. Ahmed‚Ä†, and Z. Wang‚Ä†, ‚Äú3D-NOD:  3D New Organ Detection in Plant Growth by a Spatiotemporal Point Cloud Deep Segmentation Framework,‚Äù <font color="#5B00AE"><i>Plant Phenomics</i></font>, 2025, Vol. 7, No. 1, 100002. (‚Ä†Contributed equally).</p>

[[Paper](https://www.sciencedirect.com/science/article/pii/S2643651525000081)]

[[11-minute presentation](https://www.bilibili.com/video/BV1HGktYoEwP/)]

[[Code](https://github.com/zingersu/3D-New-Organ-Detection-in-Plant-Growth-from-Spatiotemporal-Point-Clouds)]

<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="3D-NOD1.gif" width="85%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="3D-NOD2.jpg" width="85%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="3D-NOD3.jpg" width="85%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<p>[2] <b>D. Li</b>‚Ä†, L. Liu‚Ä†, S. Xu, and S. Jin*, ‚ÄúTrackPlant3D: 3D organ growth tracking framework for organ-level dynamic phenotyping,‚Äù <font color="#5B00AE"><i>Computers and Electronics in Agriculture</i></font>, Vol. 226, 2024, 109435. (‚Ä†Contributed equally).</p>

[[12-minute presentation](https://www.bilibili.com/video/BV1mKYSeZErt)]

[[Code](https://github.com/entarot/TrackPlant3D-3D-organ-growth-tracking-framework-for-organ-level-dynamic-phenotyping )]

<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="TrackPlant3D2.jpg" width="65%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="TrackPlant3D1.jpg" width="85%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>

<p>[3] <b>D. Li</b>‚Ä†, Z. Zhou‚Ä†, and Y. Wei, ‚ÄúUnsupervised shape-aware SOM down-sampling for plant point clouds,‚Äù <font color="#5B00AE"><i>ISPRS Journal of Photogrammetry and Remote Sensing</i></font>, vol. 211, 2024, pp. 172-207. (‚Ä†Contributed equally)</p>

[[Paper](https://doi.org/10.1016/j.isprsjprs.2024.03.024)]

[[10-minute presentation](https://www.bilibili.com/video/BV1LTg4enEM5/)]

[[Code](https://github.com/chinazhouzhaoyi/SOM-down-sampling-for-plant-point-clouds/)]

<table border="0">
  <tr>
     <td width="70%" align="right">
      <img src="SOMÂ±ïÁ§∫Âõæ1a.jpg" width="84%" /> 
    </td>
    <td width="30%">
      <img src="SOMËø≠‰ª£.gif" width="100%" /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="SOMÂ±ïÁ§∫Âõæ1b.jpg" width="85%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="SOMÂ±ïÁ§∫Âõæ2.jpg" width="60%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="SOMÂ±ïÁ§∫Âõæ3.jpg" width="98%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>

<p>[4] <b>D. Li</b>, Y. Wei, and R. Zhu, ‚ÄúA comparative study on point cloud down-sampling strategies for deep learning-based crop organ segmentation,‚Äù <font color="#5B00AE"><i>Plant Methods</i></font>, vol. 19, Article No. 124, 2023. </p>

[[Paper](https://link.springer.com/article/10.1186/s13007-023-01099-7/)]

[[Code](https://github.com/WeiyongchangChina/A-comparative-study-on-point-cloud-down-sampling-strategies-for-deep-learning-based-crop-organ-seg/)]

<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="ÈôçÈááÊ†∑Â±ïÁ§∫Âõæ1.jpg" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="ÈôçÈááÊ†∑Â±ïÁ§∫Âõæ2.jpg" width="54%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>

<p>[5] <b>D. Li</b>, J. Li, S. Xiang, and A. Pan, ‚ÄúPSegNet: simultaneous semantic and instance segmentation for point clouds of plants,‚Äù <font color="#5B00AE"><i>Plant Phenomics</i></font>, 2022, Article ID: 9787643.</p>

[[Paper](https://spj.science.org/doi/10.34133/2022/9787643)]

[[10-minute presentation](https://www.bilibili.com/video/BV1EEaTedE4a/)]

[[Code](https://github.com/Huang2002200/PlantNet-and-PSegNet/)]

<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="PSegNetÂ±ïÁ§∫Âõæ1.jpg" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="PSegNetÂ±ïÁ§∫Âõæ2.jpg" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="PSegNetÂ±ïÁ§∫Âõæ3.jpg" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>

<!-- Ê≥®ÈáäÊéâËØ•ÈÉ®ÂàÜ
<table border="0">
  <tr>
     <td width="55%">
      <img src="PSegNetÂ±ïÁ§∫Âõæ2.jpg" width="100%" /> 
    </td>
    <td width="45%">
      <img src="PSegNetÂ±ïÁ§∫Âõæ3.jpg" width="100%" /> 
    </td>
  </tr>
</table>
-->

<p>[6] <b>D. Li</b>‚Ä†, F. Ahmed‚Ä†, N. Wu, and A. I. Sethi, ‚ÄúYOLO-JD: A Deep Learning Network for Jute Diseases and Pests Detection from Images,‚Äù <font color="#5B00AE"><i>Plants</i></font>, vol. 11, no. 7: 937, 2022. (‚Ä†Contributed equally)</p>

[[Code](https://github.com/foysalahmed10/YOLO-JD)]

<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="JuteÂ±ïÁ§∫Âõæ1.jpg" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="JuteÂ±ïÁ§∫Âõæ2.jpg" width="60%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>

<p>[7] <b>D. Li</b>‚Ä†, S. Wang‚Ä†, S. Xiang, J. Li, Y. Yang, and X.-S. Tang, ‚ÄúDual-stream shadow detection network ‚Äì biologically inspired shadow detection for remote sensing images,‚Äù <font color="#5B00AE"><i>Neural Computing and Applications</i></font>, vol. 34, 10039-10049, 2022. (‚Ä†Contributed equally)</p>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="DSSDNÂ±ïÁ§∫Âõæ1.jpg" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="DSSDNÂ±ïÁ§∫Âõæ2.jpg" width="75%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>

<p>[8] <b>D. Li</b>‚Ä†, G. Shi‚Ä†, J. Li, Y. Chen, S. Zhang, S. Xiang, and S. Jin, ‚ÄúPlantNet: A dual-function point cloud segmentation network for multiple plant species‚Äù,  <font color="#5B00AE"><i>ISPRS Journal of Photogrammetry and Remote Sensing</i></font>, vol. 184, 2022, pp. 243-263. (‚Ä†Contributed equally)</p>

[[Paper](https://www.sciencedirect.com/science/article/abs/pii/S0924271622000119)]

[[Code](https://github.com/Huang2002200/PlantNet-and-PSegNet/)]

<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="PlantNetÂ±ïÁ§∫Âõæ1.jpg" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
     <td width="50%">
      <img src="PlantNetÂ±ïÁ§∫Âõæ2.jpg" width="100%" /> 
    </td>
    <td width="50%">
      <img src="PlantNetÂ±ïÁ§∫Âõæ3.jpg" width="100%" /> 
    </td>
  </tr>
</table>

<p>[9] X.-S. Tang, X. Xie, K. Hao, <b>D. Li</b>*, and M. Zhao, ‚ÄúA line-segment-based non-maximum suppression method for accurate object detection,‚Äù  <font color="#5B00AE"><i>Knowledge-Based Systems</i></font>, vol. 251, no. 5, 2022, 108885.</p>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="KBSÂ±ïÁ§∫Âõæ1.jpg" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="KBSÂ±ïÁ§∫Âõæ2.jpg" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>

<p>[10] <b>D. Li</b>, G. Shi, Y. Wu, Y. Yang, and M. Zhao, ‚ÄúMulti-scale neighborhood feature extraction and aggregation for point cloud segmentation‚Äù, <font color="#5B00AE"><i>IEEE Transactions on Circuits and Systems for Video Technology</i></font>, vol. 31, no. 6, 2021, pp. 2175-2191.</p>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="MNFEAMÂ±ïÁ§∫Âõæ1.jpg" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="MNFEAMÂ±ïÁ§∫Âõæ2.gif" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="MNFEAMÂ±ïÁ§∫Âõæ3.jpg" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>

<p>[11] <b>D. Li</b>, S. Yan, M. Zhao, and T.W.S. Chow, ‚ÄúSpatiotemporal Tree Filtering for Enhancing Image Change Detection‚Äù, <font color="#5B00AE"><i>IEEE Transactions on Image Processing</i></font>, vol. 29, pp. 8805-8820, 2020.</p>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="FSTFÂ±ïÁ§∫Âõæ1.jpg" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="FSTFÂ±ïÁ§∫Âõæ2.jpg" width="100%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="FSTFÂ±ïÁ§∫Âõæ3.jpg" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>

<p>[12] <b>D. Li</b>, S. Wang, X.-S. Tang, W. Kong, G. Shi, and Y. Chen, ‚ÄúDouble-stream Atrous Network for Shadow Detection,‚Äù <font color="#5B00AE"><i>Neurocomputing</i></font>, vol. 317, 2020, pp. 167-175.</p>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="DSANÂ±ïÁ§∫Âõæ1.jpg" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="DSANÂ±ïÁ§∫Âõæ2.jpg" width="95%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="DSANÂ±ïÁ§∫Âõæ3.gif" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="DSANÂ±ïÁ§∫Âõæ4.gif" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>

<p>[13] <b>D. Li</b>, G. Shi, W. Kong, S. Wang, and Y. Chen, ‚ÄúA leaf segmentation and phenotypic feature extraction framework for Multi-View Stereo plant point clouds,‚Äù <font color="#5B00AE"><i>IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing</i></font>, vol. 13, 2020, pp. 2321-2336.</p>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="JSTARSÂ±ïÁ§∫Âõæ1.jpg" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="JSTARSÂ±ïÁ§∫Âõæ2.gif" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="JSTARSÂ±ïÁ§∫Âõæ3.jpg" width="80%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>

<p>[14] <b>D. Li</b>, Y. Cao, G. Shi, X. Cai, Y. Chen, S. Wang, and S. Yan, ‚ÄúAn overlapping-free leaf segmentation method for plant point clouds,‚Äù <font color="#5B00AE"><i>IEEE Access</i></font>, vol. 7, no. 9, pp. 129054-129070, 2019.</p>

[[A 6-minute presentation](https://www.bilibili.com/video/BV11JveeDEeF/)]

[[Paper](https://ieeexplore.ieee.org/abstract/document/8830350)]

<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="O-fÂ±ïÁ§∫Âõæ1.jpg" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="O-fÂ±ïÁ§∫Âõæ2.jpg" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="O-fÂ±ïÁ§∫Âõæ3.gif" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>

<p>[15] <b>D. Li</b>, S. Yan, X. Cai, Y. Cao, and S. Wang, ‚ÄúAn Integrated image filter for enhancing change detection results,‚Äù <font color="#5B00AE"><i>IEEE Access</i></font>, vol. 7, no. 1, pp. 91034-91051, 2019.</p>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="IFÂ±ïÁ§∫Âõæ1.jpg" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="IFÂ±ïÁ§∫Âõæ2.jpg" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>

<p>[16] <b>D. Li</b>, Y. Cao, X.-S. Tang, S. Yan, and X. Cai, ‚ÄúLeaf Segmentation on Dense Plant Point Clouds with Facet Region Growing,‚Äù <font color="#5B00AE"><i>Sensors</i></font>, vol. 18, no. 11, Article 3625, 2018.</p>

[[3-minute presentation](https://www.bilibili.com/video/BV1qyv4enExL)]

[[Paper](https://www.mdpi.com/356514)]

<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="FACETSÂ±ïÁ§∫Âõæ1.jpg" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="FACETSÂ±ïÁ§∫Âõæ2.gif" width="60%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>

<p>[17] <b>D. Li</b>, L. Xu, X. Tang, S. Sun, X. Cai, and P. Zhang, ‚Äú3D Imaging of Greenhouse Plants with an Inexpensive Binocular Stereo Vision System,‚Äù <font color="#5B00AE"><i>Remote Sensing</i></font>, vol. 9, no. 5, Article 508, 2017.</p>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="RSÂ±ïÁ§∫Âõæ1.jpg" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="RSÂ±ïÁ§∫Âõæ2.jpg" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="RSÂ±ïÁ§∫Âõæ3.gif" width="60%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>

<p>[18] <b>D. Li</b>, L. Xu, and H. Liu, ‚ÄúDetection of Uneaten Fish Food Pellets in Underwater Images for Aquaculture,‚Äù <font color="#5B00AE"><i>Aquacultural Engineering</i></font>, vol. 78, Part B, pp. 85-94, 2017.</p>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="AQUAÂ±ïÁ§∫Âõæ1.jpg" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="AQUAÂ±ïÁ§∫Âõæ2.jpg" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>

<p>[19] Y. Su, L. Xu, and <b>D. Li</b>, ‚ÄúAdaptive Fuzzy Control of a Class of MIMO Nonlinear System with Actuator Saturation for Greenhouse Climate Control Problem,‚Äù <font color="#5B00AE"><i>IEEE Transactions on Automation Science and Engineering</i></font>, vol. 13, no. 2, 2016, pp. 772-788.</p>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="TASEÂ±ïÁ§∫Âõæ1.jpg" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="TASEÂ±ïÁ§∫Âõæ2.jpg" width="80%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>

<p>[20] <b>D. Li</b>, L. Xu, C. Tan, E.D. Goodman, D. Fu, and L. Xin, ‚ÄúDigitization and Visualization of Greenhouse Tomato Plants in Indoor Environments,‚Äù <font color="#5B00AE"><i>Sensors</i></font>, vol. 15, no. 2, 2015, pp. 4019-4051.</p>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="DVÂ±ïÁ§∫Âõæ1.jpg" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>

<p>[21] <b>D. Li</b>, L. Xu, and E. Goodman, ‚ÄúOn-line EM Variants for Multivariate Normal Mixture Model in Background Learning and Moving Foreground Detection,‚Äù <font color="#5B00AE"><i>Journal of Mathematical Imaging and Vision</i></font>, vol. 48, no. 1, 2014, pp. 114-133.</p>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="JMIVÂ±ïÁ§∫Âõæ1.jpg" width="70%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="JMIVÂ±ïÁ§∫Âõæ2.jpg" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="JMIVÂ±ïÁ§∫Âõæ3.gif" width="70%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>

<p>[22] <b>D. Li</b>, L. Xu, and E. Goodman, ‚ÄúIllumination-robust Foreground Detection in a Video Surveillance System,‚Äù <font color="#5B00AE"><i>IEEE Transactions on Circuits and Systems for Video Technology</i></font>, vol. 23, no. 10, pp. 1637-1650, 2013.</p>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="SPKÂ±ïÁ§∫Âõæ1.jpg" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="SPKÂ±ïÁ§∫Âõæ2.gif" width="80%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>

<p>[23] <b>D. Li</b>, L. Xu, E. Goodman, Y. Xu, and W. Yang, ‚ÄúIntegrating a statistical background-foreground extraction algorithm and SVM classifier for pedestrian detection and tracking‚Äù, <font color="#5B00AE"><i>Integrated Computer-Aided Engineering</i></font>, vol. 20, no.3, 2013, pp. 201-216.</p>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="ICAEÂ±ïÁ§∫Âõæ1.jpg" width="80%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>

<p>[24] <b>D. Li</b>, L. Xu, and E. Goodman, ‚ÄúOnline Background Learning for Illumination-robust Foreground Detection,‚Äù <font color="#5B00AE"><i>in: Proc. 11th International Conference on Control, Automation, Robotics and Vision (ICARCV)</i></font>, 2010, pp. 1093-1100. (<i>Finalist for Best Paper Award</i>)</p>
<table border="0">
  <tr>
    <td width="70%" align="center">
      <img alt="" src="ICARCVÂ±ïÁ§∫Âõæ1.jpg" width="100%" style="margin: 0 auto;"  /> 
    </td>
    <td width="30%" align="center">
      <img alt="" src="ICARCVÂ±ïÁ§∫Âõæ2.jpg" width="80%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>


      
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<p align="left"><b>The webpage has been visited <span id="busuanzi_value_site_pv"></span> times.</b></p>
<body>
<script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=jXbSyu9yHiqrIMG4S_wgh10OvbCo0cw11tLcV38Qv30&cl=ffffff&w=a" width="40%" style="margin: 0 auto;"></script>
</body> 
